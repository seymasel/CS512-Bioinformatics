# -*- coding: utf-8 -*-
"""HW7_NurverSeyma_Sel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oAaE4gOLniANqDoiFodxC1RwW0lqgkbO

Nurver Seyma Sel 27927 hw7
https://colab.research.google.com/drive/1oAaE4gOLniANqDoiFodxC1RwW0lqgkbO?usp=sharing
"""

#k-MeansClusteringProblem
from collections import defaultdict
import math

def EuclideanDistance(p1, p2):
    distance = 0
    for i in range(len(p1)):
        distance = distance + (p1[i] - p2[i]) ** 2
    return math.sqrt(distance)

def ClosestCenter(point, centers):
    minimum_dist = float("Inf")
    for x in centers:
        current = EuclideanDistance(x, point)
        if current < minimum_dist:
            minimum_dist = current
            closest = x
    return closest

def ClusterMean(cluster):
    m = len(cluster[0])
    center = [0] * m
    for point in cluster:
        for i in range(m):
            center[i] = center[i] + point[i]
    center = [x / len(cluster) for x in center]
    return center

def KmeansClustering(data, k):
    centers = data[:k]
    while True:
        #Assign Centers to clusters
        cluster_assignments = defaultdict(list)
        for point in data:
            center = ClosestCenter(point, centers)
            cluster_assignments[tuple(center)].append(point)

        #Assign Clusters to centers
        new_centers = [[]] * k
        for i in range(k):
            new_centers[i] = ClusterMean(cluster_assignments[tuple(centers[i])])

        if new_centers == centers:
            break
        centers = new_centers[:]
    return centers

points = [(1.3, 1.1), (1.3, 0.2),(0.6, 2.8),(3.0, 3.2),(1.2, 0.7),(1.4 ,1.6),(1.2, 1.0),(1.2, 1.1),(0.6, 1.5),(1.8, 2.6),(1.2, 1.3),(1.2, 1.0),(0.0, 1.9)]
KmeansClustering(points,2)

#HierarchicalClusteringProblem
def HierarchicalClustering(distance_mat,k):
    clusters = [[i] for i in range(k)]
    new_clusters_list = []
    while len(clusters) != 1:
        min_dist = float('inf') 
        for i in range(len(clusters) - 1):
            for j in range(i + 1, len(clusters)):
              dist = -1
              for index1 in clusters[i]:
                for index2 in clusters[j]:
                    dist = dist + distance_mat[index1][index2]
                    dist = dist / (len(clusters[i]) * len(clusters[j]))

            if dist < min_dist:
                    min_dist = dist
                    closest_index1 = i
                    closest_index2 = j

        
        new_cluster = clusters[closest_index1] + clusters[closest_index2] # Merge 2 closest clusters
        clusters = [clu for clu in clusters if clu not in [clusters[closest_index1], clusters[closest_index2]]]
        clusters.append(new_cluster)
        new_clusters_list.append(new_cluster)
    return new_clusters_list




rows = 7
cols = 7
mat = [[0 for _ in range(cols)] for _ in range(rows)]
mat[0][0], mat[0][1], mat[0][2], mat[0][3], mat[0][4], mat[0][5], mat[0][6] = 0.00, 0.74, 0.85, 0.54, 0.83, 0.92, 0.89
mat[1][0], mat[1][1], mat[1][2], mat[1][3], mat[1][4], mat[1][5], mat[1][6] = 0.74, 0.00, 1.59, 1.35, 1.20, 1.48, 1.55
mat[2][0], mat[2][1], mat[2][2], mat[2][3], mat[2][4], mat[2][5], mat[2][6] = 0.85, 1.59, 0.00, 0.63, 1.13, 0.69, 0.73
mat[3][0], mat[3][1], mat[3][2], mat[3][3], mat[3][4], mat[3][5], mat[3][6] = 0.54, 1.35, 0.63, 0.00, 0.66, 0.43, 0.88
mat[4][0], mat[4][1], mat[4][2], mat[4][3], mat[4][4], mat[4][5], mat[4][6] = 0.83, 1.20, 1.13, 0.66, 0.00, 0.72, 0.55
mat[5][0], mat[5][1], mat[5][2], mat[5][3], mat[5][4], mat[5][5], mat[5][6] = 0.92, 1.48, 0.69, 0.43, 0.72, 0.00, 0.80
mat[6][0], mat[6][1], mat[6][2], mat[6][3], mat[6][4], mat[6][5], mat[6][6] = 0.89, 1.55, 0.73, 0.88, 0.55, 0.80, 0.00
print(f'matrix of dimension {rows} x {cols} is {mat}')
HierarchicalClustering(mat,7)